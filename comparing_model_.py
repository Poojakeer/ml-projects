# -*- coding: utf-8 -*-
"""comparing model .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JSSYPSd12QT-dcynjvfvsv1Sq5cgAsXj
"""

# Import your libraries and data
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.metrics import accuracy_score

a=pd.read_csv('/content/bank_marketing.csv')
a.head()

# Choose the dependent and Independent variables
X = a[['age','marital','ever_defaulted','housing_loan','Personal_loan']]
Y = a[['y']]

#Train, test/validation split
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.20, 
random_state = 42)
test_df = pd.concat ([X_test,y_test],axis =1 )

# Initialize and train your model by random forest
clf = RandomForestClassifier(random_state = 42) 
clf.fit(X_train, y_train)

# Predict the test data based on the trained model
rf_pred = clf.predict(X_test)
accuracy_score(y_test, rf_pred)

# Initialize and train your model by gradient boosting
gbcl = GradientBoostingClassifier(random_state = 42)
gbcl.fit(X_train, y_train)

# Predict the test data based on the trained model
gbcl_pred = gbcl.predict(X_test)
accuracy_score(y_test, gbcl_pred)

"""The conclusion shows that GradientBoostingclassifier has 
87.12% accuracy bank marketing data

"""

